{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a88d590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488\n",
      "488\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_aug = pd.read_csv('D:/Si-Ware/488/Aug/DL_FreshCS_train_Multiple_Refs_Aug.csv')\n",
    "df_488 = pd.read_csv('D:/Si-Ware/488/target_train_488.csv')\n",
    "print(n_unique_ids := df_488['Moi'].nunique())  # Should print 488\n",
    "print(n_unique_ids_aug := df_aug['Moi'].nunique())  # Should print 488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e50e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Dataset Shape: (89793, 262)\n",
      "   Scanner ID           Sample ID        Moi  3921.568654  3935.185205  \\\n",
      "0           0  Fermented_#_519374  65.916589     7.942349     7.879306   \n",
      "1           0  Fermented_#_519374  65.916589     7.419641     7.349567   \n",
      "2           0  Fermented_#_519374  65.916589     7.505473     7.453863   \n",
      "3           0  Fermented_#_519374  65.916589     7.501803     7.404250   \n",
      "4           0  Fermented_#_519374  65.916589     7.249132     7.194527   \n",
      "\n",
      "   3948.801765  3962.418316  3976.034876  3989.651427  4003.267987  ...  \\\n",
      "0     7.818098     7.758485     7.708171     7.678701     7.680419  ...   \n",
      "1     7.286254     7.220075     7.152485     7.093691     7.057814  ...   \n",
      "2     7.412702     7.378596     7.353883     7.344609     7.357666  ...   \n",
      "3     7.300882     7.197936     7.111502     7.058376     7.048282  ...   \n",
      "4     7.142602     7.090535     7.044868     7.017365     7.019569  ...   \n",
      "\n",
      "   7312.090937  7325.707497  7339.324048  7352.940608  7366.557159  \\\n",
      "0    29.563827    30.078988    30.546206    30.978860    31.386878   \n",
      "1    31.657065    32.168421    32.636662    33.087229    33.531162   \n",
      "2    29.009951    29.480590    29.909929    30.302208    30.666498   \n",
      "3    30.556176    31.034004    31.470861    31.893944    32.316505   \n",
      "4    28.492752    28.871351    29.224750    29.601149    30.024162   \n",
      "\n",
      "   7380.173719  7393.790269  7407.406829    NDF  Starch  \n",
      "0    31.777386    32.156782    32.532960  34.34   37.86  \n",
      "1    33.970926    34.407003    34.843520  34.34   37.86  \n",
      "2    31.019581    31.383385    31.778342  34.34   37.86  \n",
      "3    32.741858    33.169309    33.600686  34.34   37.86  \n",
      "4    30.489263    30.971840    31.443427  34.34   37.86  \n",
      "\n",
      "[5 rows x 262 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df_spectral = pd.read_csv('D:/Si-Ware/488/Aug/DL_FreshCS_train_Multiple_Refs_Aug.csv')\n",
    "df_targets = pd.read_csv('D:/Si-Ware/488/target_train_488.csv')\n",
    "\n",
    "# Select only the necessary columns (Scanner ID, NDF, Starch)\n",
    "df_targets_subset = df_targets[['Moi', 'NDF', 'Starch']]\n",
    "\n",
    "# Merge on Scanner ID, ensuring no duplication of rows\n",
    "merged_df = pd.merge(df_spectral, df_targets_subset, on='Moi', how='inner')\n",
    "\n",
    "# Verify that the merged dataset has the expected size (89793, 263)\n",
    "print(f\"Merged Dataset Shape: {merged_df.shape}\")\n",
    "\n",
    "# Check the first few rows of the merged dataset\n",
    "print(merged_df.head())\n",
    "\n",
    "# Optionally, save the merged dataset\n",
    "merged_df.to_csv('D:/Si-Ware/488/finally_merged_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "632e2e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Dataset Shape: (89793, 262)\n",
      "Augmented Dataset Shape: (89793, 260)\n",
      "Do all 'Moi' values in the merged dataset exist in the spectral dataset: True\n",
      "Do all 'Moi' values in the merged dataset exist in the target dataset: True\n",
      "Missing NDF or Starch values in merged dataset:\n",
      "NDF       0\n",
      "Starch    0\n",
      "dtype: int64\n",
      "Unique 'Moi' values in merged dataset: 488\n",
      "Unique 'Moi' values in target dataset: 488\n",
      "Are the unique 'Moi' values identical: True\n",
      "First few rows of the merged dataset:\n",
      "   Scanner ID           Sample ID        Moi  3921.568654  3935.185205  \\\n",
      "0           0  Fermented_#_519374  65.916589     7.942349     7.879306   \n",
      "1           0  Fermented_#_519374  65.916589     7.419641     7.349567   \n",
      "2           0  Fermented_#_519374  65.916589     7.505473     7.453863   \n",
      "3           0  Fermented_#_519374  65.916589     7.501803     7.404250   \n",
      "4           0  Fermented_#_519374  65.916589     7.249132     7.194527   \n",
      "\n",
      "   3948.801765  3962.418316  3976.034876  3989.651427  4003.267987  ...  \\\n",
      "0     7.818098     7.758485     7.708171     7.678701     7.680419  ...   \n",
      "1     7.286254     7.220075     7.152485     7.093691     7.057814  ...   \n",
      "2     7.412702     7.378596     7.353883     7.344609     7.357666  ...   \n",
      "3     7.300882     7.197936     7.111502     7.058376     7.048282  ...   \n",
      "4     7.142602     7.090535     7.044868     7.017365     7.019569  ...   \n",
      "\n",
      "   7312.090937  7325.707497  7339.324048  7352.940608  7366.557159  \\\n",
      "0    29.563827    30.078988    30.546206    30.978860    31.386878   \n",
      "1    31.657065    32.168421    32.636662    33.087229    33.531162   \n",
      "2    29.009951    29.480590    29.909929    30.302208    30.666498   \n",
      "3    30.556176    31.034004    31.470861    31.893944    32.316505   \n",
      "4    28.492752    28.871351    29.224750    29.601149    30.024162   \n",
      "\n",
      "   7380.173719  7393.790269  7407.406829    NDF  Starch  \n",
      "0    31.777386    32.156782    32.532960  34.34   37.86  \n",
      "1    33.970926    34.407003    34.843520  34.34   37.86  \n",
      "2    31.019581    31.383385    31.778342  34.34   37.86  \n",
      "3    32.741858    33.169309    33.600686  34.34   37.86  \n",
      "4    30.489263    30.971840    31.443427  34.34   37.86  \n",
      "\n",
      "[5 rows x 262 columns]\n",
      "First few rows of the augmented dataset (Moi, NDF, Starch):\n",
      "         Moi    NDF  Starch\n",
      "0  60.823286  35.56   37.20\n",
      "1  50.485837  29.28   45.84\n",
      "2  63.115711  41.44   33.25\n",
      "3  65.419594  39.32   32.91\n",
      "4  62.917114  31.35   41.55\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df_spectral = pd.read_csv('D:/Si-Ware/488/Aug/DL_FreshCS_train_Multiple_Refs_Aug.csv')\n",
    "df_targets = pd.read_csv('D:/Si-Ware/488/target_train_488.csv')\n",
    "\n",
    "# Strip leading/trailing spaces from column names\n",
    "df_spectral.columns = df_spectral.columns.str.strip()\n",
    "df_targets.columns = df_targets.columns.str.strip()\n",
    "\n",
    "# Select only the necessary columns (Moi, NDF, Starch) from the target dataset\n",
    "df_targets_subset = df_targets[['Moi', 'NDF', 'Starch']]\n",
    "\n",
    "# Merge the datasets based on 'Moi'\n",
    "merged_df = pd.merge(df_spectral, df_targets_subset, on='Moi', how='inner')\n",
    "\n",
    "# Print the shape of both datasets for comparison\n",
    "print(f\"Merged Dataset Shape: {merged_df.shape}\")\n",
    "print(f\"Augmented Dataset Shape: {df_spectral.shape}\")\n",
    "\n",
    "# Check if the 'Moi' values in the merged dataset are in the augmented dataset (based on Moi)\n",
    "common_moi = merged_df['Moi'].isin(df_spectral['Moi']).all()\n",
    "print(f\"Do all 'Moi' values in the merged dataset exist in the spectral dataset: {common_moi}\")\n",
    "\n",
    "# Check if 'Moi' values match between the merged dataset and the target dataset\n",
    "common_moi_target = merged_df['Moi'].isin(df_targets['Moi']).all()\n",
    "print(f\"Do all 'Moi' values in the merged dataset exist in the target dataset: {common_moi_target}\")\n",
    "\n",
    "# Check for any missing NDF or Starch values in the merged dataset\n",
    "missing_ndf_starch = merged_df[['NDF', 'Starch']].isnull().sum()\n",
    "print(f\"Missing NDF or Starch values in merged dataset:\\n{missing_ndf_starch}\")\n",
    "\n",
    "# Check if the number of unique 'Moi' values are the same in both merged and target dataset\n",
    "merged_moi_unique = sorted(merged_df['Moi'].unique())\n",
    "target_moi_unique = sorted(df_targets['Moi'].unique())\n",
    "print(f\"Unique 'Moi' values in merged dataset: {len(merged_moi_unique)}\")\n",
    "print(f\"Unique 'Moi' values in target dataset: {len(target_moi_unique)}\")\n",
    "print(f\"Are the unique 'Moi' values identical: {merged_moi_unique == target_moi_unique}\")\n",
    "\n",
    "# Optionally, compare the first few rows of the merged dataset and the augmented dataset for a visual check\n",
    "print(f\"First few rows of the merged dataset:\\n{merged_df.head()}\")\n",
    "print(f\"First few rows of the augmented dataset (Moi, NDF, Starch):\\n{df_targets[['Moi', 'NDF', 'Starch']].head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7a70b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Moi    NDF  Starch  Scanner ID           Sample ID  3921.568654  \\\n",
      "0  65.916589  34.34   37.86           0  Fermented_#_519374     7.942349   \n",
      "1  65.916589  34.34   37.86           0  Fermented_#_519374     7.419641   \n",
      "2  65.916589  34.34   37.86           0  Fermented_#_519374     7.505473   \n",
      "3  65.916589  34.34   37.86           0  Fermented_#_519374     7.501803   \n",
      "4  65.916589  34.34   37.86           0  Fermented_#_519374     7.249132   \n",
      "\n",
      "   3935.185205  3948.801765  3962.418316  3976.034876  ...  7284.857826  \\\n",
      "0     7.879306     7.818098     7.758485     7.708171  ...    28.317286   \n",
      "1     7.349567     7.286254     7.220075     7.152485  ...    30.350159   \n",
      "2     7.453863     7.412702     7.378596     7.353883  ...    27.907187   \n",
      "3     7.404250     7.300882     7.197936     7.111502  ...    29.322861   \n",
      "4     7.194527     7.142602     7.090535     7.044868  ...    27.426496   \n",
      "\n",
      "   7298.474386  7312.090937  7325.707497  7339.324048  7352.940608  \\\n",
      "0    28.983611    29.563827    30.078988    30.546206    30.978860   \n",
      "1    31.063256    31.657065    32.168421    32.636662    33.087229   \n",
      "2    28.491096    29.009951    29.480590    29.909929    30.302208   \n",
      "3    29.997931    30.556176    31.034004    31.470861    31.893944   \n",
      "4    28.029293    28.492752    28.871351    29.224750    29.601149   \n",
      "\n",
      "   7366.557159  7380.173719  7393.790269  7407.406829  \n",
      "0    31.386878    31.777386    32.156782    32.532960  \n",
      "1    33.531162    33.970926    34.407003    34.843520  \n",
      "2    30.666498    31.019581    31.383385    31.778342  \n",
      "3    32.316505    32.741858    33.169309    33.600686  \n",
      "4    30.024162    30.489263    30.971840    31.443427  \n",
      "\n",
      "[5 rows x 262 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reorder columns to align NDF and Starch next to Moi\n",
    "columns_order = ['Moi', 'NDF', 'Starch'] + [col for col in merged_df.columns if col not in ['Moi', 'NDF', 'Starch']]\n",
    "\n",
    "# Reorder the merged dataframe\n",
    "aligned_df = merged_df[columns_order]\n",
    "\n",
    "# Verify the new column order\n",
    "print(aligned_df.head())\n",
    "\n",
    "# Save the aligned dataset in the same file (overwrite)\n",
    "aligned_df.to_csv('D:/Si-Ware/488/finally_merged_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d286e2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salma\\AppData\\Local\\Temp\\ipykernel_20888\\3249035761.py:22: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df.groupby('Scanner ID').apply(lambda x: x.sample(n=samples_per_scanner, random_state=42) if len(x) > 1 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Dataset Shape: (3025, 262)\n",
      "First few rows of the sampled dataset:\n",
      "         Moi    NDF  Starch   Scanner ID          Sample ID  3921.568654  \\\n",
      "0  66.361658  38.37   33.72 -10000000000  -10000000000_#285     4.738895   \n",
      "1  53.586944  44.61   27.57 -10000000000  -10000000000_#117    12.975832   \n",
      "2  53.586944  44.61   27.57 -10000000000  -10000000000_#114    13.294455   \n",
      "3  68.517117  42.36   28.47 -10000000000   -10000000000_#43     9.600401   \n",
      "4  47.562245  34.78   40.77 -10000000000  -10000000000_#127    12.283283   \n",
      "\n",
      "   3935.185205  3948.801765  3962.418316  3976.034876  ...  7284.857826  \\\n",
      "0     4.742040     4.745450     4.749895     4.761162  ...    20.985869   \n",
      "1    12.839286    12.707909    12.600796    12.526314  ...    48.483506   \n",
      "2    13.109947    12.936910    12.793985    12.688286  ...    45.044661   \n",
      "3     9.497107     9.385248     9.278228     9.178241  ...    35.731378   \n",
      "4    12.098176    11.933804    11.789980    11.689719  ...    42.127229   \n",
      "\n",
      "   7298.474386  7312.090937  7325.707497  7339.324048  7352.940608  \\\n",
      "0    21.411294    21.765058    22.021971    22.315147    22.537575   \n",
      "1    49.217416    49.789394    50.293935    50.725585    51.186622   \n",
      "2    45.670847    46.138669    46.544909    46.902597    47.288976   \n",
      "3    36.503413    37.141274    37.740762    38.303644    38.828230   \n",
      "4    42.781724    43.345211    43.872751    44.376181    44.863505   \n",
      "\n",
      "   7366.557159  7380.173719  7393.790269  7407.406829  \n",
      "0    22.779193    22.988512    23.204958    23.371916  \n",
      "1    51.696597    52.293494    52.870176    53.452588  \n",
      "2    47.720657    48.186413    48.656755    49.184660  \n",
      "3    39.382436    39.983867    40.554459    41.165236  \n",
      "4    45.357710    45.810348    46.296573    46.786665  \n",
      "\n",
      "[5 rows x 262 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Load the merged dataset (contains Moi, NDF, Starch, and spectral features)\n",
    "df = pd.read_csv('D:/Si-Ware/488/Augmented_dataset_3_targets.csv')\n",
    "\n",
    "\n",
    "# Strip leading/trailing spaces from column names (just in case)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Create a 'Sample ID' for original and augmented scanners (assuming Scanner ID is present)\n",
    "df['Sample ID'] = df['Scanner ID'].astype(str) + \"_#\" + (df.groupby('Scanner ID').cumcount() + 1).astype(str)\n",
    "\n",
    "# Calculate the number of rows you want (~3000) and divide by the number of unique scanners\n",
    "target_rows = 3000\n",
    "unique_scanners = df['Scanner ID'].nunique()\n",
    "\n",
    "# Calculate how many augmented samples per original scanner we need to select\n",
    "samples_per_scanner = int(np.ceil(target_rows / unique_scanners))\n",
    "\n",
    "# Sample the required number of augmented scanners (samples_per_scanner) per original scanner group\n",
    "df_sampled = df.groupby('Scanner ID').apply(lambda x: x.sample(n=samples_per_scanner, random_state=42) if len(x) > 1 else x)\n",
    "\n",
    "# Reset the index after applying the sampling function\n",
    "df_sampled = df_sampled.reset_index(drop=True)\n",
    "\n",
    "# Check the shape of the sampled dataset to ensure it's correct\n",
    "print(f\"Sampled Dataset Shape: {df_sampled.shape}\")\n",
    "\n",
    "# Verify the first few rows of the sampled dataset\n",
    "print(f\"First few rows of the sampled dataset:\\n{df_sampled.head()}\")\n",
    "\n",
    "# Optionally, save the sampled dataset to the same file (overwrite)\n",
    "df_sampled.to_csv('D:/Si-Ware/488/finally_sampled_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb6ef726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the sampled dataset: 3025\n",
      "First few sampled counts per Scanner ID:\n",
      " Scanner ID\n",
      "-10000000000    25\n",
      " 5021060004     25\n",
      " 7022030100     25\n",
      " 7021100018     25\n",
      " 7021100008     25\n",
      "                ..\n",
      " 2021100006     25\n",
      " 2021100002     25\n",
      " 2021060017     25\n",
      " 2021060010     25\n",
      " 10022030101    25\n",
      "Name: count, Length: 121, dtype: int64\n",
      "Total number of rows sampled: 3025\n",
      "Number of unique Scanner IDs in the sampled dataset: 121\n",
      "Are all Scanner IDs sampled with 3 samples? False\n",
      "First few rows of the sampled dataset:\n",
      "         Moi    NDF  Starch   Scanner ID          Sample ID  3921.568654  \\\n",
      "0  66.361658  38.37   33.72 -10000000000  -10000000000_#285     4.738895   \n",
      "1  53.586944  44.61   27.57 -10000000000  -10000000000_#117    12.975832   \n",
      "2  53.586944  44.61   27.57 -10000000000  -10000000000_#114    13.294455   \n",
      "3  68.517117  42.36   28.47 -10000000000   -10000000000_#43     9.600401   \n",
      "4  47.562245  34.78   40.77 -10000000000  -10000000000_#127    12.283283   \n",
      "\n",
      "   3935.185205  3948.801765  3962.418316  3976.034876  ...  7284.857826  \\\n",
      "0     4.742040     4.745450     4.749895     4.761162  ...    20.985869   \n",
      "1    12.839286    12.707909    12.600796    12.526314  ...    48.483506   \n",
      "2    13.109947    12.936910    12.793985    12.688286  ...    45.044661   \n",
      "3     9.497107     9.385248     9.278228     9.178241  ...    35.731378   \n",
      "4    12.098176    11.933804    11.789980    11.689719  ...    42.127229   \n",
      "\n",
      "   7298.474386  7312.090937  7325.707497  7339.324048  7352.940608  \\\n",
      "0    21.411294    21.765058    22.021971    22.315147    22.537575   \n",
      "1    49.217416    49.789394    50.293935    50.725585    51.186622   \n",
      "2    45.670847    46.138669    46.544909    46.902597    47.288976   \n",
      "3    36.503413    37.141274    37.740762    38.303644    38.828230   \n",
      "4    42.781724    43.345211    43.872751    44.376181    44.863505   \n",
      "\n",
      "   7366.557159  7380.173719  7393.790269  7407.406829  \n",
      "0    22.779193    22.988512    23.204958    23.371916  \n",
      "1    51.696597    52.293494    52.870176    53.452588  \n",
      "2    47.720657    48.186413    48.656755    49.184660  \n",
      "3    39.382436    39.983867    40.554459    41.165236  \n",
      "4    45.357710    45.810348    46.296573    46.786665  \n",
      "\n",
      "[5 rows x 262 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of rows\n",
    "print(f\"Total number of rows in the sampled dataset: {df_sampled.shape[0]}\")\n",
    "\n",
    "# Verify how many samples were selected per Scanner ID\n",
    "sampled_counts = df_sampled['Scanner ID'].value_counts()\n",
    "\n",
    "# Check the first few rows of the sampled counts to verify how many rows were sampled per Scanner ID\n",
    "print(\"First few sampled counts per Scanner ID:\\n\", sampled_counts)\n",
    "\n",
    "# Check if the total number of rows matches the expected (~3000)\n",
    "print(f\"Total number of rows sampled: {sampled_counts.sum()}\")\n",
    "\n",
    "# Check the number of unique Scanner IDs\n",
    "unique_scanners_sampled = sampled_counts.count()\n",
    "print(f\"Number of unique Scanner IDs in the sampled dataset: {unique_scanners_sampled}\")\n",
    "\n",
    "# Verify if the number of samples per Scanner ID is as expected\n",
    "# For example, if you want approximately 3 samples per original scanner, check if that holds\n",
    "expected_samples_per_scanner = 3\n",
    "consistent_samples = sampled_counts.apply(lambda x: x == expected_samples_per_scanner).all()\n",
    "print(f\"Are all Scanner IDs sampled with {expected_samples_per_scanner} samples? {consistent_samples}\")\n",
    "\n",
    "# Optionally, check the first few rows of the sampled dataset to visually inspect\n",
    "print(f\"First few rows of the sampled dataset:\\n{df_sampled.head()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
