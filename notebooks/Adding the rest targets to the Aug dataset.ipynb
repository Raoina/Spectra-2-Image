{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa623359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salma\\AppData\\Local\\Temp\\ipykernel_5480\\3900181876.py:11: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_df = pd.merge(df_spectral, df_targets, on='Scanner ID', how='inner')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Scanner ID Sample ID      Moi_x  3921.568654_x  3935.185205_x  \\\n",
      "0           0           0      0_#1  65.916589       7.942349       7.879306   \n",
      "1           0           0      0_#1  65.916589       7.942349       7.879306   \n",
      "2           0           0      0_#1  65.916589       7.942349       7.879306   \n",
      "3           0           0      0_#1  65.916589       7.942349       7.879306   \n",
      "4           0           0      0_#1  65.916589       7.942349       7.879306   \n",
      "\n",
      "   3948.801765_x  3962.418316_x  3976.034876_x  3989.651427_x  ...  \\\n",
      "0       7.818098       7.758485       7.708171       7.678701  ...   \n",
      "1       7.818098       7.758485       7.708171       7.678701  ...   \n",
      "2       7.818098       7.758485       7.708171       7.678701  ...   \n",
      "3       7.818098       7.758485       7.708171       7.678701  ...   \n",
      "4       7.818098       7.758485       7.708171       7.678701  ...   \n",
      "\n",
      "   7284.857826_y  7298.474386_y  7312.090937_y  7325.707497_y  7339.324048_y  \\\n",
      "0      29.061569      29.719695      30.282829      30.776051      31.221689   \n",
      "1      28.664607      29.354309      29.941066      30.449983      30.904692   \n",
      "2      30.511725      31.154145      31.689698      32.151423      32.570211   \n",
      "3      41.556666      42.177963      42.684349      43.113982      43.507174   \n",
      "4      38.723702      39.315012      39.801505      40.216857      40.595816   \n",
      "\n",
      "   7352.940608_y  7366.557159_y  7380.173719_y  7393.790269_y  7407.406829_y  \n",
      "0      31.636271      32.031861      32.418576      32.805999      33.203861  \n",
      "1      31.323142      31.718571      32.102393      32.486204      32.882728  \n",
      "2      32.967507      33.355418      33.739725      34.123693      34.511823  \n",
      "3      43.894237      44.291796      44.703396      45.124190      45.548199  \n",
      "4      40.964286      41.336491      41.716004      42.099884      42.485067  \n",
      "\n",
      "[5 rows x 521 columns]\n",
      "Merged Dataset Shape: (408523, 521)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df_spectral = pd.read_csv('D:/Si-Ware/488/Aug/DL_FreshCS_train_Multiple_Refs_Aug.csv')\n",
    "df_targets = pd.read_csv('D:/Si-Ware/488/train_df_averaged.csv')\n",
    "\n",
    "# Create a 'Sample ID' by appending an index to the Scanner ID to identify augmented versions\n",
    "df_spectral['Sample ID'] = df_spectral['Scanner ID'].astype(str) + \"_#\" + (df_spectral.groupby('Scanner ID').cumcount() + 1).astype(str)\n",
    "\n",
    "# Now merge the datasets using this new Sample ID\n",
    "merged_df = pd.merge(df_spectral, df_targets, on='Scanner ID', how='inner')\n",
    "\n",
    "# Display the first few rows of the merged dataset\n",
    "print(merged_df.head())\n",
    "\n",
    "# Optionally, save the merged dataset\n",
    "merged_df.to_csv('D:/Si-Ware/488/merged_dataset.csv', index=False)\n",
    "\n",
    "# Check the shape of the merged dataset\n",
    "print(f\"Merged Dataset Shape: {merged_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e77aeded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408523, 521)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented = merged_df.copy()\n",
    "df_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2639b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Dataset Columns: Index(['Unnamed: 0', 'Scanner ID', 'Sample ID', 'Moi', '3921.568654',\n",
      "       '3935.185205', '3948.801765', '3962.418316', '3976.034876',\n",
      "       '3989.651427',\n",
      "       ...\n",
      "       '7284.857826', '7298.474386', '7312.090937', '7325.707497',\n",
      "       '7339.324048', '7352.940608', '7366.557159', '7380.173719',\n",
      "       '7393.790269', '7407.406829'],\n",
      "      dtype='object', length=261)\n",
      "Target Dataset Columns: Index(['Scanner ID', 'Moi', 'NDF', 'Starch', '3921.568654', '3935.185205',\n",
      "       '3948.801765', '3962.418316', '3976.034876', '3989.651427',\n",
      "       ...\n",
      "       '7284.857826', '7298.474386', '7312.090937', '7325.707497',\n",
      "       '7339.324048', '7352.940608', '7366.557159', '7380.173719',\n",
      "       '7393.790269', '7407.406829'],\n",
      "      dtype='object', length=261)\n"
     ]
    }
   ],
   "source": [
    "# Check column names in both datasets\n",
    "print(\"Spectral Dataset Columns:\", df_spectral.columns)\n",
    "print(\"Target Dataset Columns:\", df_targets.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a71f97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salma\\AppData\\Local\\Temp\\ipykernel_5480\\2138546022.py:8: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_df = pd.merge(df_spectral, df_targets, on='Scanner ID', how='inner')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Scanner ID           Sample ID      Moi_x  3921.568654_x  \\\n",
      "0           0           0  Fermented_#_519374  65.916589       7.942349   \n",
      "1           0           0  Fermented_#_519374  65.916589       7.942349   \n",
      "2           0           0  Fermented_#_519374  65.916589       7.942349   \n",
      "3           0           0  Fermented_#_519374  65.916589       7.942349   \n",
      "4           0           0  Fermented_#_519374  65.916589       7.942349   \n",
      "\n",
      "   3935.185205_x  3948.801765_x  3962.418316_x  3976.034876_x  3989.651427_x  \\\n",
      "0       7.879306       7.818098       7.758485       7.708171       7.678701   \n",
      "1       7.879306       7.818098       7.758485       7.708171       7.678701   \n",
      "2       7.879306       7.818098       7.758485       7.708171       7.678701   \n",
      "3       7.879306       7.818098       7.758485       7.708171       7.678701   \n",
      "4       7.879306       7.818098       7.758485       7.708171       7.678701   \n",
      "\n",
      "   ...  7284.857826_y  7298.474386_y  7312.090937_y  7325.707497_y  \\\n",
      "0  ...      29.061569      29.719695      30.282829      30.776051   \n",
      "1  ...      28.664607      29.354309      29.941066      30.449983   \n",
      "2  ...      30.511725      31.154145      31.689698      32.151423   \n",
      "3  ...      41.556666      42.177963      42.684349      43.113982   \n",
      "4  ...      38.723702      39.315012      39.801505      40.216857   \n",
      "\n",
      "   7339.324048_y  7352.940608_y  7366.557159_y  7380.173719_y  7393.790269_y  \\\n",
      "0      31.221689      31.636271      32.031861      32.418576      32.805999   \n",
      "1      30.904692      31.323142      31.718571      32.102393      32.486204   \n",
      "2      32.570211      32.967507      33.355418      33.739725      34.123693   \n",
      "3      43.507174      43.894237      44.291796      44.703396      45.124190   \n",
      "4      40.595816      40.964286      41.336491      41.716004      42.099884   \n",
      "\n",
      "   7407.406829_y  \n",
      "0      33.203861  \n",
      "1      32.882728  \n",
      "2      34.511823  \n",
      "3      45.548199  \n",
      "4      42.485067  \n",
      "\n",
      "[5 rows x 521 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Optionally, save the merged dataset\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:/Si-Ware/488/merged_dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Check the shape of the merged dataset\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerged Dataset Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmerged_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:3986\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3975\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3977\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3978\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3979\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3983\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3984\u001b[0m )\n\u001b[1;32m-> 3986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3989\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3991\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4003\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:320\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    317\u001b[0m slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[0;32m    318\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[slicer]\n\u001b[1;32m--> 320\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[0;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:1410\u001b[0m, in \u001b[0;36mDataFrame._get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_values_for_csv\u001b[39m(\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1402\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;66;03m# helper used by to_csv\u001b[39;00m\n\u001b[1;32m-> 1410\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"DataFrame\", expected \"Self\")\u001b[39;00m\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:466\u001b[0m, in \u001b[0;36mBaseBlockManager.get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    461\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m    462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_values_for_csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\blocks.py:806\u001b[0m, in \u001b[0;36mBlock.get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    804\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[0;32m    805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[1;32m--> 806\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:7904\u001b[0m, in \u001b[0;36mget_values_for_csv\u001b[1;34m(values, date_format, na_rep, quoting, float_format, decimal)\u001b[0m\n\u001b[0;32m   7901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   7902\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7904\u001b[0m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m na_rep\n\u001b[0;32m   7905\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   7906\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df_spectral = pd.read_csv('D:/Si-Ware/488/Aug/DL_FreshCS_train_Multiple_Refs_Aug.csv')\n",
    "df_targets = pd.read_csv('D:/Si-Ware/488/train_df_averaged.csv')\n",
    "\n",
    "# Merge on Sample ID (to match targets with spectral data)\n",
    "merged_df = pd.merge(df_spectral, df_targets, on='Scanner ID', how='inner')\n",
    "\n",
    "# Display merged data for verification\n",
    "print(merged_df.head())\n",
    "\n",
    "# Optionally, save the merged dataset\n",
    "merged_df.to_csv('D:/Si-Ware/488/merged_dataset.csv', index=False)\n",
    "\n",
    "# Check the shape of the merged dataset\n",
    "print(f\"Merged Dataset Shape: {merged_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "237be784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (784, 261)\n",
      "Augmented DataFrame shape: (89793, 261)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_augmented = pd.read_csv('D:/Si-Ware/488/Aug/DL_FreshCS_train_Multiple_Refs_Aug.csv')\n",
    "original_df = pd.read_csv('D:/Si-Ware/488/train_df_averaged.csv')\n",
    "print(\"Original DataFrame shape:\", original_df.shape)\n",
    "print(\"Augmented DataFrame shape:\", df_augmented.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f75d18d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset details saved to dataset_info.txt. Please share the content with me.\n"
     ]
    }
   ],
   "source": [
    "dataset_info = {\n",
    "    'Shape': df_augmented.shape,  # Number of rows and columns\n",
    "    'Columns': df_augmented.columns.tolist(),  # Column names\n",
    "    'Data Types': df_augmented.dtypes.tolist(),  # Data types of each column\n",
    "    'Missing Values': df_augmented.isnull().sum().tolist(),  # Missing values count per column\n",
    "    'Sample Data': df_augmented.sample(5).to_dict(orient='records')  # 5 random sample rows\n",
    "}\n",
    "\n",
    "# Save the output to a text file for easy sharing\n",
    "output_file = 'dataset_info.txt'\n",
    "with open(output_file, 'w') as f:\n",
    "    for key, value in dataset_info.items():\n",
    "        f.write(f\"{key}:\\n{value}\\n\\n\")\n",
    "\n",
    "print(f\"Dataset details saved to {output_file}. Please share the content with me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2101a923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Sample ID: 784\n",
      "Unique Scanner ID: 121\n",
      "Unique Scanner ID in original df: 22\n"
     ]
    }
   ],
   "source": [
    "# count unique values in the two columns\n",
    "sample_unique = df_augmented['Sample ID'].nunique()\n",
    "scanner_unique = df_augmented['Scanner ID'].nunique()\n",
    "scanner_unique_2 = original_df['Scanner ID'].nunique()\n",
    "\n",
    "print(f\"Unique Sample ID: {sample_unique}\")\n",
    "print(f\"Unique Scanner ID: {scanner_unique}\")\n",
    "print(f\"Unique Scanner ID in original df: {scanner_unique_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a759424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 89793 samples.\n",
      "Final sampled size: 2352 samples (Expected: 2352)\n",
      "Number of original groups kept: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salma\\AppData\\Local\\Temp\\ipykernel_5480\\2223976059.py:29: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(min(len(x), MAX_SAMPLES_PER_ID), random_state=42))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Path to your full 89K augmented dataset's metadata (e.g., a CSV file)\n",
    "FULL_METADATA_PATH = \"D:/Si-Ware/488/Aug/DL_FreshCS_train_Multiple_Refs_Aug.csv\"\n",
    "\n",
    "# Path where all 89K image files currently reside\n",
    "FULL_IMAGE_DIR = \"path/to/all_89k_plots\"\n",
    "\n",
    "# The directory where you want to save the new 2,352 samples and metadata\n",
    "NEW_DATASET_DIR = \"D:/Si-Ware/488/Aug\" \n",
    "\n",
    "MAX_SAMPLES_PER_ID = 3 \n",
    "ORIGINAL_ID_COLUMN = 'Sample ID' # Make sure this matches your column name\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "df_augmented = pd.read_csv(FULL_METADATA_PATH)\n",
    "\n",
    "# --- 2. Sample 3 Samples per Original ID (Leakage-Proof Sampling) ---\n",
    "print(f\"Original dataset size: {len(df_augmented)} samples.\")\n",
    "\n",
    "# Apply .sample() to each group, ensuring we pick at most MAX_SAMPLES_PER_ID\n",
    "df_final_sample = (\n",
    "    df_augmented\n",
    "    .groupby(ORIGINAL_ID_COLUMN, group_keys=False) \n",
    "    .apply(lambda x: x.sample(min(len(x), MAX_SAMPLES_PER_ID), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "N_final = len(df_final_sample)\n",
    "N_original_groups = df_final_sample[ORIGINAL_ID_COLUMN].nunique()\n",
    "\n",
    "print(f\"Final sampled size: {N_final} samples (Expected: 2352)\")\n",
    "print(f\"Number of original groups kept: {N_original_groups}\")\n",
    "\n",
    "# Check for correctness: should be 784 * 3 = 2352 if all originals had 3+ augmented versions\n",
    "if N_final > (784 * 3):\n",
    "    print(\"WARNING: Sample size is unexpectedly large. Check your original_id column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499b7f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the sampled data to: D:/Si-Ware/488/Aug/Sub_Aug.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory and filename\n",
    "output_dir = 'D:/Si-Ware/488/Aug/'\n",
    "file_name = 'Sub_Aug.csv'\n",
    "\n",
    "# Construct the full file path\n",
    "full_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "# Ensure the directory exists (important if you're running this on a local machine)\n",
    "# In the Colab environment, this path refers to the mounted Windows drive structure \n",
    "# if you've set up tools like Rclone, but generally, Colab files are local to the environment.\n",
    "# Assuming you are running this in a *local* Python environment or a configured environment:\n",
    "os.makedirs(output_dir, exist_ok=True) \n",
    "\n",
    "# Save the DataFrame to the specified path\n",
    "df_final_sample.to_csv(full_path, index=False)\n",
    "\n",
    "print(f\"Successfully saved the sampled data to: {full_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0acc227a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved target to: D:/Si-Ware/488/Aug/Sub_Aug_target.csv\n",
      "Saved spectra (257 columns) to: D:/Si-Ware/488/Aug/Sub_Aug_spectra.csv\n"
     ]
    }
   ],
   "source": [
    "# Create two CSVs: Sub_Aug_target.csv (contains 'Moi') and Sub_Aug_spectra.csv (all numeric spectral columns)\n",
    "# Assumes df_final_sample, output_dir, os and np are already defined in the notebook\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1) Target file with only the 'Moi' column\n",
    "target_df = df_final_sample[['Moi']].copy()\n",
    "target_path = os.path.join(output_dir, 'Sub_Aug_target.csv')\n",
    "target_df.to_csv(target_path, index=False)\n",
    "\n",
    "# 2) Spectra file: all numeric columns except identifiers and the target 'Moi'\n",
    "numeric_cols = df_final_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
    "exclude = {'Unnamed: 0', 'Scanner ID', 'Moi'}  # drop identifier ints and the target column\n",
    "spectra_cols = [c for c in numeric_cols if c not in exclude]\n",
    "spectra_df = df_final_sample[spectra_cols].copy()\n",
    "\n",
    "spectra_path = os.path.join(output_dir, 'Sub_Aug_spectra.csv')\n",
    "spectra_df.to_csv(spectra_path, index=False)\n",
    "\n",
    "print(f\"Saved target to: {target_path}\")\n",
    "print(f\"Saved spectra ({len(spectra_cols)} columns) to: {spectra_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f4d222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in target: 3672; rows with matched NDF/Starch: 2721; missing: 951\n",
      "Saved matched file to: D:/Si-Ware/488/Aug/Sub_Aug_target_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Match Moi from Sub_Aug_target (target_df) with train_df_averaged and save NDF & Starch alongside Moi.\n",
    "# Uses existing variables: target_df, output_dir (from earlier cells).\n",
    "\n",
    "TRAIN_AVG_PATH = \"D:/Si-Ware/488/train_df_averaged.csv\"\n",
    "OUT_FILE = os.path.join(output_dir, \"Sub_Aug_target_2.csv\")\n",
    "\n",
    "# Load averaged training metadata\n",
    "train_avg = pd.read_csv(TRAIN_AVG_PATH)\n",
    "\n",
    "# Identify columns for Moi, NDF and Starch (case-insensitive match with fallback to substring)\n",
    "def find_col(df_cols, name):\n",
    "    name_l = name.lower()\n",
    "    exact = [c for c in df_cols if c.lower() == name_l]\n",
    "    if exact:\n",
    "        return exact[0]\n",
    "    contains = [c for c in df_cols if name_l in c.lower()]\n",
    "    return contains[0] if contains else None\n",
    "\n",
    "cols = train_avg.columns.tolist()\n",
    "col_map = {\n",
    "    'Moi': find_col(cols, 'Moi'),\n",
    "    'NDF': find_col(cols, 'NDF'),\n",
    "    'Starch': find_col(cols, 'Starch')\n",
    "}\n",
    "\n",
    "missing = [k for k,v in col_map.items() if v is None]\n",
    "if missing:\n",
    "    raise ValueError(f\"Could not find columns for: {missing} in {TRAIN_AVG_PATH}. Available columns: {cols}\")\n",
    "\n",
    "# Prepare dataframes for merge\n",
    "left = target_df.reset_index(drop=True).copy()  # contains 'Moi'\n",
    "right = train_avg[[col_map['Moi'], col_map['NDF'], col_map['Starch']]].copy()\n",
    "right = right.rename(columns={col_map['Moi']: 'Moi', col_map['NDF']: 'NDF', col_map['Starch']: 'Starch'})\n",
    "\n",
    "# Merge on Moi (left join to keep all target rows)\n",
    "merged = left.merge(right, on='Moi', how='left')\n",
    "\n",
    "# Report how many matched vs missing\n",
    "n_total = len(merged)\n",
    "n_matched = merged['NDF'].notna().sum()  # assume NDF present iff matched\n",
    "print(f\"Total rows in target: {n_total}; rows with matched NDF/Starch: {n_matched}; missing: {n_total - n_matched}\")\n",
    "\n",
    "# Save result\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "merged.to_csv(OUT_FILE, index=False)\n",
    "print(f\"Saved matched file to: {OUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d9d9301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge performed using Moi rounded to 4 decimal places.\n",
      "Total rows in target: 6798; rows with matched NDF/Starch: 6798; missing: 0\n",
      "Saved matched file to: D:/Si-Ware/488/Aug/Sub_Aug_target_3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "TRAIN_AVG_PATH = \"D:/Si-Ware/488/train_df_averaged.csv\"\n",
    "OUT_FILE = os.path.join(output_dir, \"Sub_Aug_target_3.csv\")\n",
    "ROUNDING_PLACES = 4 # Adjust this value based on the required precision\n",
    "\n",
    "# Load averaged training metadata\n",
    "train_avg = pd.read_csv(TRAIN_AVG_PATH)\n",
    "\n",
    "# --- 1. Identify Columns (Original Logic) ---\n",
    "def find_col(df_cols, name):\n",
    "    name_l = name.lower()\n",
    "    exact = [c for c in df_cols if c.lower() == name_l]\n",
    "    if exact:\n",
    "        return exact[0]\n",
    "    contains = [c for c in df_cols if name_l in c.lower()]\n",
    "    return contains[0] if contains else None\n",
    "\n",
    "cols = train_avg.columns.tolist()\n",
    "col_map = {\n",
    "    'Moi': find_col(cols, 'Moi'),\n",
    "    'NDF': find_col(cols, 'NDF'),\n",
    "    'Starch': find_col(cols, 'Starch')\n",
    "}\n",
    "\n",
    "missing = [k for k,v in col_map.items() if v is None]\n",
    "if missing:\n",
    "    raise ValueError(f\"Could not find columns for: {missing} in {TRAIN_AVG_PATH}. Available columns: {cols}\")\n",
    "\n",
    "# --- 2. Prepare Dataframes for Approximate Merge ---\n",
    "left = target_df.reset_index(drop=True).copy()  # contains 'Moi'\n",
    "right = train_avg[[col_map['Moi'], col_map['NDF'], col_map['Starch']]].copy()\n",
    "\n",
    "# Rename the columns in the right DF for a clean merge\n",
    "right = right.rename(columns={\n",
    "    col_map['Moi']: 'Moi_Original', # Preserve the original value\n",
    "    col_map['NDF']: 'NDF', \n",
    "    col_map['Starch']: 'Starch'\n",
    "})\n",
    "\n",
    "# Create a temporary rounded 'Moi' column for merging in both DFs\n",
    "left['Moi_Rounded'] = left['Moi'].round(ROUNDING_PLACES)\n",
    "right['Moi_Rounded'] = right['Moi_Original'].round(ROUNDING_PLACES)\n",
    "\n",
    "# --- 3. Merge on Rounded Moi (Left Join) ---\n",
    "# We merge on the rounded column to perform an approximate match\n",
    "merged = left.merge(\n",
    "    right[['Moi_Rounded', 'NDF', 'Starch']], \n",
    "    on='Moi_Rounded', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Clean up by dropping the temporary rounded column\n",
    "merged = merged.drop(columns=['Moi_Rounded'])\n",
    "# Note: Moi column in 'merged' now contains the original floating point value from target_df\n",
    "\n",
    "# --- 4. Reporting and Saving ---\n",
    "n_total = len(merged)\n",
    "n_matched = merged['NDF'].notna().sum()  # assume NDF present iff matched\n",
    "print(f\"Merge performed using Moi rounded to {ROUNDING_PLACES} decimal places.\")\n",
    "print(f\"Total rows in target: {n_total}; rows with matched NDF/Starch: {n_matched}; missing: {n_total - n_matched}\")\n",
    "\n",
    "# Save result\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "merged.to_csv(OUT_FILE, index=False)\n",
    "print(f\"Saved matched file to: {OUT_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
