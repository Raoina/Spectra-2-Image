{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raoina/Spectra-2-Image/blob/main/notebooks/Models/2D_CNN_CR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D-CNN pipeline (images ready)"
      ],
      "metadata": {
        "id": "VR_YzA5UMs1c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RemCAvt3Mn5I"
      },
      "outputs": [],
      "source": [
        "# ====== Imports ======\n",
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import iqr\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Colab drive mount ======\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brBmYwlvM4EB",
        "outputId": "56ae4fb8-f0db-4412-b5eb-2b4716ccc1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Paths ======\n",
        "IMG_DIR = \"/content/drive/MyDrive/CR_train_65x65\"\n",
        "CSV_PATH = \"/content/drive/MyDrive/train_Moi_NDF_Starch.csv\"\n",
        "\n",
        "TARGETS = ['Moi',       'NDF',  'Starch']\n",
        "IMG_SIZE = 65 #------------------------------------------>16"
      ],
      "metadata": {
        "id": "ksNI9-DvNDr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Hyperparams ======\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "lr = 0.0001\n",
        "n_splits = 5\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-_WZq0VOu-L",
        "outputId": "cdaff048-9b2a-4189-f418-ebc4eb27a5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Load CSV ======\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "# df = df.dropna(subset=TARGETS).reset_index(drop=True)\n",
        "print(\"Data shape:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOB0AAJCO1n1",
        "outputId": "90f4c04a-9bca-4dd0-c542-e29f232dcb49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (784, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Scale targets ======\n",
        "y_scaler = MinMaxScaler()\n",
        "targets_scaled = y_scaler.fit_transform(df[TARGETS].values.astype(np.float32))"
      ],
      "metadata": {
        "id": "bT-SOcwyPE-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Dataset class (images already ready) ======\n",
        "class SoilImageDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, targets_scaled, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.targets = targets_scaled.astype(np.float32)\n",
        "        self.transform = transform if transform else transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, f\"CUT_{idx}.png\")  # assume  0.png, 1.png ...\n",
        "        img = Image.open(img_path).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))  # grayscale\n",
        "        img = self.transform(img)  # shape (1,H,W)\n",
        "        target = torch.from_numpy(self.targets[idx])\n",
        "        return img, target\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # (H,W) -> (1,H,W), float in [0,1]\n",
        "])\n",
        "\n",
        "dataset = SoilImageDataset(df, IMG_DIR, targets_scaled, transform=transform)\n",
        "print(\"Dataset length:\", len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNATOPpIPK1-",
        "outputId": "05facd4a-58f4-4491-a910-e723e544917e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length: 784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CNN model (as in Table 2) ======\n",
        "class CNN2D(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_outputs=3): # Changed num_outputs to 3\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv3a = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv3b = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv4a = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.conv4b = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5a = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5b = nn.Conv2d(512, 512, 3, padding=1)\n",
        "\n",
        "        self.flattened = 512 * 2 * 2\n",
        "        self.fc1 = nn.Linear(self.flattened, 128)\n",
        "        self.fc2 = nn.Linear(128, num_outputs)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x)); x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x)); x = self.pool(x)\n",
        "        x = self.relu(self.conv3a(x)); x = self.relu(self.conv3b(x)); x = self.pool(x)\n",
        "        x = self.relu(self.conv4a(x)); x = self.relu(self.conv4b(x)); x = self.pool(x)\n",
        "        x = self.relu(self.conv5a(x)); x = self.relu(self.conv5b(x)); x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "YcJBoJ1GPg4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Metrics ======\n",
        "def compute_metrics_orig(y_true, y_pred):\n",
        "    results = []\n",
        "    for i in range(y_true.shape[1]):\n",
        "        yt, yp = y_true[:, i], y_pred[:, i]\n",
        "        rmse = np.sqrt(mean_squared_error(yt, yp))\n",
        "        r2 = r2_score(yt, yp)\n",
        "        rpiq = float(iqr(yt) / rmse) if rmse > 1e-8 else float(\"inf\")\n",
        "        results.append({\"RMSE\": rmse, \"R2\": r2, \"RPIQ\": rpiq})\n",
        "    return results"
      ],
      "metadata": {
        "id": "ssBFdxxRPyXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Split train/test ======\n",
        "indices = np.arange(len(dataset))\n",
        "trainval_idx, test_idx = train_test_split(indices, test_size=0.3, random_state=seed)"
      ],
      "metadata": {
        "id": "WoPpVKiIQBFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 5-Fold CV ======\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "for fold, (t_idx, v_idx) in enumerate(kf.split(trainval_idx)):\n",
        "    print(f\"\\n--- Fold {fold+1}/{n_splits} ---\")\n",
        "    train_loader = DataLoader(Subset(dataset, trainval_idx[t_idx]), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(Subset(dataset, trainval_idx[v_idx]), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = CNN2D().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(xb), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            preds = model(xb.to(device)).cpu().numpy()\n",
        "            yb_np = yb.cpu().numpy()\n",
        "            preds_orig = y_scaler.inverse_transform(preds)\n",
        "            yb_orig = y_scaler.inverse_transform(yb_np)\n",
        "            y_true.append(yb_orig); y_pred.append(preds_orig)\n",
        "    y_true, y_pred = np.vstack(y_true), np.vstack(y_pred)\n",
        "    metrics = compute_metrics_orig(y_true, y_pred)\n",
        "    for i, t in enumerate(TARGETS):\n",
        "        print(f\"{t}: RMSE={metrics[i]['RMSE']:.3f}, R2={metrics[i]['R2']:.3f}, RPIQ={metrics[i]['RPIQ']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgTF6fYoQGF3",
        "outputId": "e5d91a19-6eb6-40da-f14f-9674ca242fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fold 1/5 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ====== Train final on all trainval + test evaluation ======\n",
        "final_loader = DataLoader(Subset(dataset, trainval_idx), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(Subset(dataset, test_idx), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "final_model = CNN2D().to(device)\n",
        "optimizer = torch.optim.Adam(final_model.parameters(), lr=lr)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    final_model.train()\n",
        "    for xb, yb in final_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(final_model(xb), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Test\n",
        "final_model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        preds = final_model(xb.to(device)).cpu().numpy()\n",
        "        yb_np = yb.cpu().numpy()\n",
        "        preds_orig = y_scaler.inverse_transform(preds)\n",
        "        yb_orig = y_scaler.inverse_transform(yb_np)\n",
        "        y_true.append(yb_orig); y_pred.append(preds_orig)\n",
        "y_true, y_pred = np.vstack(y_true), np.vstack(y_pred)\n",
        "test_metrics = compute_metrics_orig(y_true, y_pred)\n",
        "\n",
        "print(\"\\n== Test metrics ==\")\n",
        "for i, t in enumerate(TARGETS):\n",
        "    print(f\"{t}: RMSE={test_metrics[i]['RMSE']:.3f}, R2={test_metrics[i]['R2']:.3f}, RPIQ={test_metrics[i]['RPIQ']:.3f}\")\n",
        "\n",
        "torch.save(final_model.state_dict(), \"/content/2d_cnn_images_ready.pth\")\n",
        "print(\"Saved model to /content/2d_cnn_images_ready.pth\")"
      ],
      "metadata": {
        "id": "kYtpCczZQTrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5d41492"
      },
      "source": [
        "# ====== Average Calibration Metrics ======\n",
        "# The current code doesn't explicitly have a 'calibration_results' variable.\n",
        "# Assuming the 'metrics' from the last fold of the CV loop in cell 'QgTF6fYoQGF3'\n",
        "# are representative of calibration or a final training step before test evaluation.\n",
        "# I will use the test_metrics from cell 'kYtpCczZQTrS' as the final evaluation metrics.\n",
        "\n",
        "# Calculate bias for test set\n",
        "def compute_bias(y_true, y_pred):\n",
        "    bias = np.mean(y_pred - y_true, axis=0)\n",
        "    return bias\n",
        "\n",
        "test_bias = compute_bias(y_true, y_pred)\n",
        "\n",
        "\n",
        "# Create DataFrame for Test metrics\n",
        "test_metrics_df = []\n",
        "for i, col in enumerate(TARGETS):\n",
        "    test_metrics_df.append({'Property': col, 'RMSE': test_metrics[i]['RMSE'], 'R²': test_metrics[i]['R2'], 'Bias': test_bias[i]})\n",
        "test_metrics_df = pd.DataFrame(test_metrics_df)\n",
        "# Reorder columns for Test metrics\n",
        "test_metrics_df = test_metrics_df[['Property', 'R²', 'RMSE', 'Bias']]\n",
        "\n",
        "print(\"\\n=== Test Set Metrics ===\")\n",
        "display(test_metrics_df)\n",
        "\n",
        "# Note: The provided notebook structure performs k-fold cross-validation\n",
        "# and then a final training on the combined train+validation set followed by test evaluation.\n",
        "# There isn't a separate \"calibration\" set or explicit calculation of\n",
        "# average CV metrics across all folds stored in a single variable like `fold_results`.\n",
        "# If you need average CV metrics, we would need to modify the CV loop\n",
        "# to store the metrics from each fold."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}